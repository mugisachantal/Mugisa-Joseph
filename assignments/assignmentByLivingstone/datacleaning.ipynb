{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc70d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_mine=pd.read_csv('Mine.csv')\n",
    "df_sales=pd.read_csv('Sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac1bad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      " Duration    0\n",
      "Date        2\n",
      "Pulse       1\n",
      "Maxpulse    2\n",
      "Calories    4\n",
      "dtype: int64\n",
      "checking for Missing values after handling:\n",
      " Duration    0\n",
      "Date        2\n",
      "Pulse       0\n",
      "Maxpulse    0\n",
      "Calories    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values before handling:\\n\",df_mine.isnull().sum())\n",
    "for col in ['Duration', 'Pulse', 'Maxpulse', 'Calories']:\n",
    "     if df_mine[col].dtype in ['int64', 'float64']:\n",
    "      df_mine[col]=df_mine[col].fillna(df_mine[col].mean())\n",
    "     else: \n",
    "       df_mine[col]=df_mine[col].fillna(df_mine[col].mode()[0])\n",
    "print(\"checking for Missing values after handling:\\n\",df_mine.isnull().sum())       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d39d20ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      " Order ID         0\n",
      "Customer Name    1\n",
      "Order Date       0\n",
      "Product          0\n",
      "Quantity         1\n",
      "Unit Price       1\n",
      "Total Revenue    1\n",
      "dtype: int64\n",
      "checking for Missing values after handling:\n",
      " Order ID         0\n",
      "Customer Name    0\n",
      "Order Date       0\n",
      "Product          0\n",
      "Quantity         0\n",
      "Unit Price       0\n",
      "Total Revenue    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAKOS\\AppData\\Local\\Temp\\ipykernel_17108\\2348644191.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_sales[col].fillna(df_sales[col].mean(), inplace=True)\n",
      "C:\\Users\\MAKOS\\AppData\\Local\\Temp\\ipykernel_17108\\2348644191.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_sales[col].fillna(df_sales[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values before handling:\\n\",df_sales.isnull().sum())\n",
    "for col in ['Order ID','Customer Name','Order Date','Product','Quantity','Unit Price','Total Revenue']:\n",
    "    if df_sales[col].dtype in ['int64', 'float64']:\n",
    "      df_sales[col].fillna(df_sales[col].mean(), inplace=True)\n",
    "    else: \n",
    "       df_sales[col].fillna(df_sales[col].mode()[0], inplace=True)\n",
    "print(\"checking for Missing values after handling:\\n\",df_sales.isnull().sum())       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec81cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration      int64\n",
      "Date         object\n",
      "Pulse       float64\n",
      "Maxpulse    float64\n",
      "Calories    float64\n",
      "dtype: object\n",
      "Order ID           int64\n",
      "Customer Name     object\n",
      "Order Date        object\n",
      "Product           object\n",
      "Quantity         float64\n",
      "Unit Price       float64\n",
      "Total Revenue    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_mine.dtypes)\n",
    "print(df_sales.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16bb9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Handling Inconsistent Date Formats (mine.csv):\n",
      "Original 'Date' dtype: object\n",
      "Sample of 'Date' column before conversion:\n",
      " 0    2023/10/01'\n",
      "1    2023/10/02'\n",
      "2    2023/10/03'\n",
      "3    2023/10/04'\n",
      "4    2023/10/05'\n",
      "Name: Date, dtype: object\n",
      "Missing 'Date' values after format coercion:\n",
      " 3\n",
      "Dropping rows with unparseable dates (NaT values)...\n",
      "New 'Date' dtype: datetime64[ns]\n",
      "Sample of 'Date' column after conversion:\n",
      " 0   2023-10-01\n",
      "1   2023-10-02\n",
      "2   2023-10-03\n",
      "3   2023-10-04\n",
      "4   2023-10-05\n",
      "Name: Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# 2. Inconsistent date formats (mine.csv)\n",
    "print(\"\\n2. Handling Inconsistent Date Formats (mine.csv):\")\n",
    "print(\"Original 'Date' dtype:\", df_mine['Date'].dtype)\n",
    "print(\"Sample of 'Date' column before conversion:\\n\", df_mine['Date'].head())\n",
    "\n",
    "# removing trailing single quote\n",
    "\n",
    "df_mine['Date'] = df_mine['Date'].astype(str).str.replace(\"'\", \"\")\n",
    "\n",
    "# Converting 'Date' column to datetime objects\n",
    "df_mine['Date'] = pd.to_datetime(df_mine['Date'], errors='coerce')\n",
    "\n",
    "#  dropping any new NaT values if the conversion failed\n",
    "print(\"Missing 'Date' values after format coercion:\\n\", df_mine['Date'].isnull().sum())\n",
    "if df_mine['Date'].isnull().any():\n",
    "    print(\"Dropping rows with unparseable dates (NaT values)...\")\n",
    "    df_mine.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "print(\"New 'Date' dtype:\", df_mine['Date'].dtype)\n",
    "print(\"Sample of 'Date' column after conversion:\\n\", df_mine['Date'].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0cc9590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Handling Duplicate Rows in (mine.csv):\n",
      "Number of duplicate rows before dropping: 0\n",
      "Number of duplicate rows after dropping: 0\n",
      "Shape after dropping duplicates: (28, 5)\n"
     ]
    }
   ],
   "source": [
    "# 3. Duplicate rows (mine.csv)\n",
    "print(\"\\n3. Handling Duplicate Rows in (mine.csv):\")\n",
    "print(\"Number of duplicate rows before dropping:\", df_mine.duplicated().sum())\n",
    "df_mine.drop_duplicates(inplace=True)\n",
    "print(\"Number of duplicate rows after dropping:\", df_mine.duplicated().sum())\n",
    "print(\"Shape after dropping duplicates:\", df_mine.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcb35c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Handling Wrong Data (mine.csv):\n",
      "Capped 1 'Duration' values greater than 180 to 180.\n",
      "\n",
      "--- Cleaned mine.csv DataFrame ---\n",
      "    Duration       Date       Pulse    Maxpulse    Calories\n",
      "0         60 2023-10-01  110.000000  130.000000  409.100000\n",
      "1         60 2023-10-02  117.000000  145.000000  479.000000\n",
      "2         60 2023-10-03  103.000000  135.000000  340.300000\n",
      "3         45 2023-10-04  109.000000  175.000000  282.400000\n",
      "4         45 2023-10-05  117.000000  150.000000  405.100000\n",
      "5         60 2023-10-06  103.000000  125.000000  300.000000\n",
      "6         60 2023-10-07  110.000000  135.000000  374.000000\n",
      "7        180 2023-10-08  114.000000  133.000000  302.859259\n",
      "8         60 2023-10-09  112.000000  126.000000  193.800000\n",
      "9         30 2023-10-10  102.000000  147.000000  234.800000\n",
      "10        60 2023-10-11  100.000000  129.000000  375.300000\n",
      "11        60 2023-10-12  109.000000  131.000000  345.600000\n",
      "12        60 2023-10-13  103.000000  136.000000  239.200000\n",
      "13        60 2023-10-15  120.000000  123.241379  240.800000\n",
      "14        60 2023-10-15  120.000000  100.000000  240.800000\n",
      "15        60 2023-10-16  118.833333  101.000000  243.800000\n",
      "16        60 2023-10-17  127.000000  102.000000  380.200000\n",
      "18        60 2023-10-19  151.000000  104.000000  302.859259\n",
      "19        60 2023-10-20  162.000000  105.000000  300.900000\n",
      "20        60 2023-10-21  100.000000  106.000000  280.000000\n",
      "21        60 2023-10-22  103.000000  107.000000  302.859259\n",
      "23        60 2023-10-24  134.000000  123.241379  239.700000\n",
      "24        60 2023-10-25  132.000000  110.000000  236.900000\n",
      "25        60 2023-10-26  135.000000  118.000000  278.800000\n",
      "26        60 2023-10-27  137.000000  119.000000  212.900000\n",
      "27        60 2023-10-28  138.000000  121.000000  345.900000\n",
      "28        60 2023-10-29  139.000000  122.000000  345.200000\n",
      "30        60 2023-10-31   94.000000  126.000000  302.859259\n",
      "\n",
      "Final Missing values check (mine.csv):\n",
      " Duration    0\n",
      "Date        0\n",
      "Pulse       0\n",
      "Maxpulse    0\n",
      "Calories    0\n",
      "dtype: int64\n",
      "\n",
      "Final Dtypes (mine.csv):\n",
      " Duration             int64\n",
      "Date        datetime64[ns]\n",
      "Pulse              float64\n",
      "Maxpulse           float64\n",
      "Calories           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 4. Wrong data (mine.csv)\n",
    "print(\"\\n4. Handling Wrong Data (mine.csv):\")\n",
    "\n",
    "\n",
    "initial_long_duration_count = df_mine[df_mine['Duration'] > 180].shape[0]\n",
    "if initial_long_duration_count > 0:\n",
    "    df_mine['Duration'] = np.where(df_mine['Duration'] > 180, 180, df_mine['Duration'])\n",
    "    print(f\"Capped {initial_long_duration_count} 'Duration' values greater than 180 to 180.\")\n",
    "else:\n",
    "    print(\"No 'Duration' values greater than 180 found to cap.\")\n",
    "\n",
    "# making  all numerical columns numeric type after all operations\n",
    "for col in ['Duration', 'Pulse', 'Maxpulse', 'Calories']:\n",
    "    if col in df_mine.columns:\n",
    "        df_mine[col] = pd.to_numeric(df_mine[col], errors='coerce')\n",
    "        if df_mine[col].isnull().any():\n",
    "            mean_val = df_mine[col].mean()\n",
    "            df_mine[col].fillna(mean_val, inplace=True)\n",
    "          \n",
    "\n",
    "print(\"\\n--- Cleaned mine.csv DataFrame ---\")\n",
    "print(df_mine)\n",
    "print(\"\\nFinal Missing values check (mine.csv):\\n\", df_mine.isnull().sum())\n",
    "print(\"\\nFinal Dtypes (mine.csv):\\n\", df_mine.dtypes)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b800653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "             CLEANING sales.csv\n",
      "==================================================\n",
      "\n",
      "1. Handling Missing Values in (sales.csv):\n",
      "Missing values before handling:\n",
      " Order ID         0\n",
      "Customer Name    0\n",
      "Order Date       0\n",
      "Product          0\n",
      "Quantity         0\n",
      "Unit Price       0\n",
      "Total Revenue    0\n",
      "dtype: int64\n",
      "Missing values after initial handling:\n",
      " Order ID         0\n",
      "Customer Name    0\n",
      "Order Date       0\n",
      "Product          0\n",
      "Quantity         0\n",
      "Unit Price       0\n",
      "Total Revenue    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Cleaning sales.csv ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"             CLEANING sales.csv\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# 1. Missing values / Empty cells (sales.csv)\n",
    "print(\"\\n1. Handling Missing Values in (sales.csv):\")\n",
    "print(\"Missing values before handling:\\n\", df_sales.isnull().sum())\n",
    "\n",
    "# 'Customer Name': Fill empty strings/NaN with 'Unknown'\n",
    "if 'Customer Name' in df_sales.columns:\n",
    "    df_sales['Customer Name'].fillna('Unknown', inplace=True)\n",
    "    df_sales['Customer Name'] = df_sales['Customer Name'].replace('', 'Unknown') # For actual empty strings\n",
    "\n",
    "# Filling empty cells with  mean.\n",
    "if 'Quantity' in df_sales.columns and df_sales['Quantity'].isnull().any():\n",
    "    median_quantity = df_sales['Quantity'].median()\n",
    "    df_sales['Quantity'].fillna(median_quantity, inplace=True)\n",
    "    print(f\"Filled missing 'Quantity' with median: {median_quantity:.0f}\")\n",
    "\n",
    "if 'Unit Price' in df_sales.columns and df_sales['Unit Price'].isnull().any():\n",
    "    median_unit_price = df_sales['Unit Price'].median()\n",
    "    df_sales['Unit Price'].fillna(median_unit_price, inplace=True)\n",
    "    print(f\"Filled missing 'Unit Price' with median: {median_unit_price:.2f}\")\n",
    "\n",
    "\n",
    "if 'Total Revenue' in df_sales.columns and df_sales['Total Revenue'].isnull().any():\n",
    "    median_total_revenue = df_sales['Total Revenue'].median()\n",
    "    df_sales['Total Revenue'].fillna(median_total_revenue, inplace=True)\n",
    "    print(f\"Filled missing 'Total Revenue' with median: {median_total_revenue:.2f}\")\n",
    "\n",
    "print(\"Missing values after initial handling:\\n\", df_sales.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc758c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Handling Inconsistent Date Formats (sales.csv):\n",
      "Original 'Order Date' dtype: object\n",
      "Sample of 'Order Date' column before conversion:\n",
      " 0     01/01/2024\n",
      "1     01/02/2024\n",
      "2    2024/01/03'\n",
      "3     04/01/2024\n",
      "4    2024/01/05'\n",
      "Name: Order Date, dtype: object\n",
      "Missing 'Order Date' values after format coercion:\n",
      " 2\n",
      "Dropping rows with unparseable 'Order Date'\n",
      "New 'Order Date' dtype: datetime64[ns]\n",
      "Sample of 'Order Date' column after conversion:\n",
      " 0   2024-01-01\n",
      "1   2024-01-02\n",
      "3   2024-04-01\n",
      "5   2024-06-01\n",
      "6   2024-01-01\n",
      "Name: Order Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# 2. Inconsistent date formats (sales.csv)\n",
    "print(\"\\n2. Handling Inconsistent Date Formats (sales.csv):\")\n",
    "print(\"Original 'Order Date' dtype:\", df_sales['Order Date'].dtype)\n",
    "print(\"Sample of 'Order Date' column before conversion:\\n\", df_sales['Order Date'].head())\n",
    "\n",
    "\n",
    "df_sales['Order Date'] = df_sales['Order Date'].astype(str).str.replace(\"'\", \"\")\n",
    "\n",
    "df_sales['Order Date'] = pd.to_datetime(df_sales['Order Date'], errors='coerce')\n",
    "\n",
    "print(\"Missing 'Order Date' values after format coercion:\\n\", df_sales['Order Date'].isnull().sum())\n",
    "if df_sales['Order Date'].isnull().any():\n",
    "    print(\"Dropping rows with unparseable 'Order Date'\")\n",
    "    df_sales.dropna(subset=['Order Date'], inplace=True)\n",
    "\n",
    "print(\"New 'Order Date' dtype:\", df_sales['Order Date'].dtype)\n",
    "print(\"Sample of 'Order Date' column after conversion:\\n\", df_sales['Order Date'].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cc1b521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Handling Duplicate Rows (sales.csv):\n",
      "Number of duplicate rows before dropping: 1\n",
      "Number of duplicate rows after dropping: 0\n",
      "Shape after dropping duplicates: (5, 7)\n"
     ]
    }
   ],
   "source": [
    "# 3. Duplicate rows (sales.csv)\n",
    "print(\"\\n3. Handling Duplicate Rows (sales.csv):\")\n",
    "print(\"Number of duplicate rows before dropping:\", df_sales.duplicated().sum())\n",
    "df_sales.drop_duplicates(inplace=True)\n",
    "print(\"Number of duplicate rows after dropping:\", df_sales.duplicated().sum())\n",
    "print(\"Shape after dropping duplicates:\", df_sales.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b31b61df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Handling Wrong Data (sales.csv):\n",
      "Replaced 1 negative 'Quantity' values with NaN.\n",
      "Filled new 'Quantity' NaNs with median: 4\n",
      "Recalculated 'Total Revenue' based on 'Quantity' * 'Unit Price'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAKOS\\AppData\\Local\\Temp\\ipykernel_17108\\886480360.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_sales['Quantity'].fillna(median_quantity_after_negative_fix, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 4. Wrong data (sales.csv)\n",
    "print(\"\\n4. Handling Wrong Data (sales.csv):\")\n",
    "if 'Quantity' in df_sales.columns:\n",
    "    initial_negative_qty_count = df_sales[df_sales['Quantity'] < 0].shape[0]\n",
    "    if initial_negative_qty_count > 0:\n",
    "        df_sales['Quantity'] = np.where(df_sales['Quantity'] < 0, np.nan, df_sales['Quantity'])\n",
    "        print(f\"Replaced {initial_negative_qty_count} negative 'Quantity' values with NaN.\")\n",
    "        # Re-impute quantity if new NaNs were created\n",
    "        if df_sales['Quantity'].isnull().any():\n",
    "            median_quantity_after_negative_fix = df_sales['Quantity'].median()\n",
    "            df_sales['Quantity'].fillna(median_quantity_after_negative_fix, inplace=True)\n",
    "            print(f\"Filled new 'Quantity' NaNs with median: {median_quantity_after_negative_fix:.0f}\")\n",
    "    else:\n",
    "        print(\"No negative 'Quantity' values found.\")\n",
    "\n",
    "# to  numeric\n",
    "for col in ['Unit Price', 'Total Revenue']:\n",
    "    if col in df_sales.columns:\n",
    "        df_sales[col] = pd.to_numeric(df_sales[col], errors='coerce')\n",
    "        if df_sales[col].isnull().any():\n",
    "            median_val = df_sales[col].median()\n",
    "            df_sales[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Ensured '{col}' is numeric and filled any new NaNs with median: {median_val:.2f}\")\n",
    "\n",
    "# Recalculating 'Total Revenue' to ensure consistency, because Quantity/Unit Price were changed\n",
    "\n",
    "if 'Quantity' in df_sales.columns and 'Unit Price' in df_sales.columns and 'Total Revenue' in df_sales.columns:\n",
    "    df_sales['Calculated Revenue'] = df_sales['Quantity'] * df_sales['Unit Price']\n",
    "   \n",
    "    print(\"Recalculated 'Total Revenue' based on 'Quantity' * 'Unit Price'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86ab1661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Removing Unnecessary Columns (sales.csv):\n",
      "Columns before dropping: ['Order ID', 'Customer Name', 'Order Date', 'Product', 'Quantity', 'Unit Price', 'Total Revenue', 'Calculated Revenue']\n",
      "No specified unnecessary columns found to drop in sales.csv.\n",
      "Columns after dropping: ['Order ID', 'Customer Name', 'Order Date', 'Product', 'Quantity', 'Unit Price', 'Total Revenue', 'Calculated Revenue']\n",
      "\n",
      "--- Cleaned sales.csv DataFrame ---\n",
      "   Order ID  Customer Name Order Date   Product  Quantity  Unit Price  \\\n",
      "0      1001       John Doe 2024-01-01  Widget A      10.0   25.000000   \n",
      "1      1002     Jane Smith 2024-01-02  Widget B       5.0   40.000000   \n",
      "3      1004  Alice Johnson 2024-04-01  Widget C       3.0   35.714286   \n",
      "5      1006       John Doe 2024-06-01  Widget A       4.0   25.000000   \n",
      "7      1007     Jane Smith 2024-07-01  Widget C       4.5   70.000000   \n",
      "\n",
      "   Total Revenue  Calculated Revenue  \n",
      "0          250.0          250.000000  \n",
      "1          200.0          200.000000  \n",
      "3          210.0          107.142857  \n",
      "5          100.0          100.000000  \n",
      "7         -420.0          315.000000  \n",
      "\n",
      "Final Missing values check (sales.csv):\n",
      " Order ID              0\n",
      "Customer Name         0\n",
      "Order Date            0\n",
      "Product               0\n",
      "Quantity              0\n",
      "Unit Price            0\n",
      "Total Revenue         0\n",
      "Calculated Revenue    0\n",
      "dtype: int64\n",
      "\n",
      "Final Dtypes (sales.csv):\n",
      " Order ID                       int64\n",
      "Customer Name                 object\n",
      "Order Date            datetime64[ns]\n",
      "Product                       object\n",
      "Quantity                     float64\n",
      "Unit Price                   float64\n",
      "Total Revenue                float64\n",
      "Calculated Revenue           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5. Unnecessary columns that are not relevant to the analysis (sales.csv)\n",
    "print(\"\\n5. Removing Unnecessary Columns (sales.csv):\")\n",
    "print(\"Columns before dropping:\", df_sales.columns.tolist())\n",
    "\n",
    "# Assuming 'Order ID' might be unique enough and not needed for aggregate analysis\n",
    "\n",
    "columns_to_drop_sales = [] # No obvious unnecessary columns in your sales.csv sample for now\n",
    "\n",
    "\n",
    "existing_columns_to_drop_sales = [col for col in columns_to_drop_sales if col in df_sales.columns]\n",
    "\n",
    "if existing_columns_to_drop_sales:\n",
    "    df_sales.drop(columns=existing_columns_to_drop_sales, inplace=True)\n",
    "    print(f\"Dropped columns: {existing_columns_to_drop_sales}\")\n",
    "else:\n",
    "    print(\"No specified unnecessary columns found to drop in sales.csv.\")\n",
    "\n",
    "print(\"Columns after dropping:\", df_sales.columns.tolist())\n",
    "\n",
    "print(\"\\n--- Cleaned sales.csv DataFrame ---\")\n",
    "print(df_sales)\n",
    "print(\"\\nFinal Missing values check (sales.csv):\\n\", df_sales.isnull().sum())\n",
    "print(\"\\nFinal Dtypes (sales.csv):\\n\", df_sales.dtypes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
